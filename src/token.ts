import { BTree } from './btree'

export function tokIsKeyword(t :token) :bool {
  return token.keyword_beg < t && t < token.keyword_end
}

export function hasIntValue(t :token) :bool {
  return t == token.CHAR
}

export function hasByteValue(t :token) :bool {
  return (
    (token.literal_beg < t && t < token.literal_end) ||
    t == token.COMMENT
  )
}

export function tokstr(t :token) :string {
  return tokenStrings.get(t) || token[t].toLowerCase()
}

// Operator precedences
export enum prec {
  LOWEST, // = := ! <- ->
  OR,     // ||
  AND,    // &&
  CMP,    // == != < <= > >=
  ADD,    // + - | ^
  MUL,    // * / % & &^ << >>
}

export enum token {
  // Special tokens
  ILLEGAL = 0,
  EOF,
  COMMENT,

  literal_beg,
  // Identifiers and basic type literals
  // (these tokens stand for classes of literals)
  NAME,    // main
  NAMEAT,  // @foo, @
  literal_int_beg,
  INT,     // 12345
  INT_BIN, // 0b1010
  INT_OCT, // 0o6737
  INT_HEX, // 0xBE3f
  literal_int_end,
  FLOAT,   // 123.45
  RATIO,   // 22/7
  CHAR,    // 'a'
  STRING,  // "abc"
  STRING_MULTI, // "ab\nc" â€” multi-line
  STRING_PIECE, // "a ${...} b" -- the "a " part (" b" is STRING)
  literal_end,

  // Delimiters
  delim_beg,
  LPAREN,    // (
  LBRACKET,  // [
  LBRACE,    // {
  COMMA,     // ,
  DOT,       // .
  PERIODS,   // ..
  ELLIPSIS,  // ...
  RPAREN,    // )
  RBRACKET,  // ]
  RBRACE,    // }
  SEMICOLON, // ;
  COLON,     // :
  delim_end,

  // Operators
  operator_beg,

  // prec.LOWEST
  ASSIGN,         // =
  assignop_beg,
  ADD_ASSIGN,     // +=
  SUB_ASSIGN,     // -=
  MUL_ASSIGN,     // *=
  QUO_ASSIGN,     // /=
  REM_ASSIGN,     // %=
  AND_ASSIGN,     // &=
  OR_ASSIGN,      // |=
  XOR_ASSIGN,     // ^=
  SHL_ASSIGN,     // <<=
  SHR_ASSIGN,     // >>=
  AND_NOT_ASSIGN, // &^=
  assignop_end,
  INC,            // ++
  DEC,            // --
  SET_ASSIGN,     // :=
  NOT,            // !
  ARROWL,         // <-
  ARROWR,         // ->

  // prec.OR
  LOR, // ||
  
  // prec.AND
  LAND, // &&

  // prec.CMP
  EQL, // ==
  NEQ, // !=
  LSS, // <
  LEQ, // <=
  GTR, // >
  GEQ, // >=
  
  // prec.ADD
  ADD, // +
  SUB, // -
  OR,  // |
  XOR, // ^
  
  // prec.MUL
  MUL,     // *
  QUO,     // /
  REM,     // %
  AND,     // &
  AND_NOT, // &^
  SHL,     // <<
  SHR,     // >>

  operator_end,

  // Keywords
  keyword_beg,
  BREAK,
  //CASE,
  //CHAN,
  //CONST,
  CONTINUE,
  DEFAULT,
  DEFER,
  ELSE,
  ENUM,
  FALLTHROUGH,
  FOR,
  FUN,
  GO,
  //GOTO,
  IF,
  IMPORT,
  INTERFACE,
  IN,
  //MAP,
  //PACKAGE,
  //RANGE,
  RETURN,
  SELECT,
  //STRUCT,
  SWITCH,
  SYMBOL,
  TYPE,
  // VAR,
  keyword_end
} // enum T


// Keywords
// When you add, change or remove a keyword, make sure to run gen-btree.js
// with the changes and update the code below.
// Keyword token names should be the UPPER-CASE version of the actual keyword
// name. This convention is used to populate tokenStrings.


const tokenStrings = new Map<token, string>([
  [token.NAMEAT, "@"],

  [token.ADD, "+"],
  [token.SUB, "-"],
  [token.MUL, "*"],
  [token.QUO, "/"],
  [token.REM, "%"],

  [token.AND,     "&"],
  [token.OR,      "|"],
  [token.XOR,     "^"],
  [token.SHL,     "<<"],
  [token.SHR,     ">>"],
  [token.AND_NOT, "&^"],

  [token.ADD_ASSIGN, "+="],
  [token.SUB_ASSIGN, "-="],
  [token.MUL_ASSIGN, "*="],
  [token.QUO_ASSIGN, "/="],
  [token.REM_ASSIGN, "%="],

  [token.AND_ASSIGN,     "&="],
  [token.OR_ASSIGN,      "|="],
  [token.XOR_ASSIGN,     "^="],
  [token.SHL_ASSIGN,     "<<="],
  [token.SHR_ASSIGN,     ">>="],
  [token.AND_NOT_ASSIGN, "&^="],

  [token.LAND,   "&&"],
  [token.LOR,    "||"],
  [token.ARROWL, "<-"],
  [token.ARROWR, "->"],
  [token.INC,    "++"],
  [token.DEC,    "--"],

  [token.EQL,    "=="],
  [token.LSS,    "<"],
  [token.GTR,    ">"],
  [token.ASSIGN, "="],
  [token.NOT,    "!"],

  [token.NEQ,        "!="],
  [token.LEQ,        "<="],
  [token.GEQ,        ">="],
  [token.SET_ASSIGN, ":="],
  [token.ELLIPSIS,   "..."],
  [token.PERIODS,    ".."],

  [token.LPAREN,   "("],
  [token.LBRACKET, "["],
  [token.LBRACE,   "{"],
  [token.COMMA,    ","],
  [token.DOT,      "."],

  [token.RPAREN,    ")"],
  [token.RBRACKET,  "]"],
  [token.RBRACE,    "}"],
  [token.SEMICOLON, ";"],
  [token.COLON,     ":"],
]) // tokenStrings

for (let i = token.keyword_beg+1; i < token.keyword_end; ++i) {
  const t = token[i] as string
  tokenStrings.set((token as any)[t] as token, t.toLowerCase())
}

// generated by gen-keywords.js
const cdat = new Uint8Array([
  102,117,110,100,101,102,101,114,98,114,101,97,107,99,111,110,116,105,110,117
  ,101,100,101,102,97,117,108,116,101,110,117,109,101,108,115,101,102,97,108
  ,108,116,104,114,111,117,103,104,102,111,114,105,110,116,101,114,102,97,99
  ,101,105,102,103,111,105,109,112,111,114,116,105,110,115,101,108,101,99,116
  ,114,101,116,117,114,110,115,119,105,116,99,104,115,121,109,98,111,108,116
  ,121,112,101]);
const keywords = new BTree<token>(
  { k: cdat.subarray(0,3) /*fun*/, v: token.FUN,
    L:{ k: cdat.subarray(3,8) /*defer*/, v: token.DEFER,
      L:{ k: cdat.subarray(8,13) /*break*/, v: token.BREAK,
        R:{ k: cdat.subarray(13,21) /*continue*/, v: token.CONTINUE,
          R:{ k: cdat.subarray(21,28) /*default*/, v: token.DEFAULT}}},
      R:{ k: cdat.subarray(28,32) /*enum*/, v: token.ENUM,
        L:{ k: cdat.subarray(32,36) /*else*/, v: token.ELSE},
        R:{ k: cdat.subarray(36,47) /*fallthrough*/, v: token.FALLTHROUGH,
          R:{ k: cdat.subarray(47,50) /*for*/, v: token.FOR}}}},
    R:{ k: cdat.subarray(50,59) /*interface*/, v: token.INTERFACE,
      L:{ k: cdat.subarray(59,61) /*if*/, v: token.IF,
        L:{ k: cdat.subarray(61,63) /*go*/, v: token.GO},
        R:{ k: cdat.subarray(63,69) /*import*/, v: token.IMPORT,
          R:{ k: cdat.subarray(69,71) /*in*/, v: token.IN}}},
      R:{ k: cdat.subarray(71,77) /*select*/, v: token.SELECT,
        L:{ k: cdat.subarray(77,83) /*return*/, v: token.RETURN},
        R:{ k: cdat.subarray(83,89) /*switch*/, v: token.SWITCH,
          R:{ k: cdat.subarray(89,95) /*symbol*/, v: token.SYMBOL,
            R:{ k: cdat.subarray(95,99) /*type*/, v: token.TYPE}}}}}}
)

// lookupKeyword maps an identifier to its keyword token or NAME
// (if not a keyword).
//
export function lookupKeyword(ident :ArrayLike<byte>) :token {
  return keywords.get(ident) || token.NAME
}
